{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6895fd34-b554-4650-81a0-755062a3c018",
   "metadata": {},
   "source": [
    "## Nadav Mashich - 209372614\n",
    "## Amit Stein - 315175315\n",
    "\n",
    "Repository - https://github.com/nadav52/Matala-2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd177d-2fdf-4c4a-b94e-5ed9ae432c0c",
   "metadata": {},
   "source": [
    "## Import Statements for Data Preparation and Elastic Net Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fdf043ea-4d49-4b51-acfd-0044cd058120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b25ddc-e814-400d-bdec-c8945f788be5",
   "metadata": {},
   "source": [
    "## Prepare the data, clean and parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8614976-3e27-4197-af11-c162a129f0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def prepare_data(df, target='Price'):\n",
    "    df = df.copy()\n",
    "\n",
    "    def clean_numeric(x):\n",
    "        \"\"\"Cleans numeric values in a DataFrame column.\"\"\"\n",
    "        if isinstance(x, str):\n",
    "            return pd.to_numeric(x.replace(',', ''), errors='coerce')\n",
    "        return x\n",
    "\n",
    "    def clean_and_impute_numeric_columns(df, numeric_columns):\n",
    "        \"\"\"Cleans and imputes numeric columns.\"\"\"\n",
    "        for col in numeric_columns:\n",
    "            df[col] = df[col].apply(clean_numeric)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "        return df\n",
    "\n",
    "    def impute_categorical_columns(df):\n",
    "        \"\"\"Imputes categorical columns with a constant value.\"\"\"\n",
    "        categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "        categorical_imputer = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
    "        df[categorical_columns] = categorical_imputer.fit_transform(df[categorical_columns])\n",
    "        return df\n",
    "\n",
    "    def convert_date_columns(df, date_columns):\n",
    "        \"\"\"Converts specified columns to datetime.\"\"\"\n",
    "        for col in date_columns:\n",
    "            df[col] = pd.to_datetime(df[col], format='%d/%m/%Y', errors='coerce')\n",
    "        return df\n",
    "\n",
    "    def create_season_column(df, date_column):\n",
    "        \"\"\"Creates a season column based on the month of a date column.\"\"\"\n",
    "        df['Season'] = df[date_column].dt.month.map({\n",
    "            12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "            3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "            6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "            9: 'Fall', 10: 'Fall', 11: 'Fall'\n",
    "        }).fillna('Unknown')\n",
    "        return df\n",
    "\n",
    "    def create_derived_features(df):\n",
    "        \"\"\"Creates derived features such as Age, Km_per_year, and Age_Hand_interaction.\"\"\"\n",
    "        current_year = pd.Timestamp.now().year\n",
    "        df['Age'] = current_year - df['Year']\n",
    "        df['Km_per_year'] = df['Km'] / (df['Age'] + 1)\n",
    "        df['Age_Hand_interaction'] = df['Age'] * df['Hand']\n",
    "        return df\n",
    "\n",
    "    def drop_unnecessary_columns(df, columns_to_drop):\n",
    "        \"\"\"Drops unnecessary columns from the DataFrame.\"\"\"\n",
    "        return df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "    # Define numeric columns\n",
    "    numeric_columns = ['capacity_Engine', 'Km', 'Pic_num', 'Year', 'Hand', target]\n",
    "\n",
    "    # Clean and impute numeric columns\n",
    "    df = clean_and_impute_numeric_columns(df, numeric_columns)\n",
    "\n",
    "    # Impute categorical columns\n",
    "    df = impute_categorical_columns(df)\n",
    "\n",
    "    # Convert date columns\n",
    "    date_columns = ['Cre_date', 'Repub_date']\n",
    "    df = convert_date_columns(df, date_columns)\n",
    "\n",
    "    # Create season column\n",
    "    df = create_season_column(df, 'Cre_date')\n",
    "\n",
    "    # Create derived features\n",
    "    df = create_derived_features(df)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = ['Cre_date', 'Repub_date', 'Description', 'Supply_score', 'Test']\n",
    "    df = drop_unnecessary_columns(df, columns_to_drop)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbecb15d-e2af-4963-b879-7d642b32e292",
   "metadata": {},
   "source": [
    "#### Key Points:\n",
    "\n",
    "1. **Data Cleaning and Imputation Functions**\n",
    "    - **`def clean_numeric`**: This function is used to clean numeric data by removing non-numeric characters and converting them to numeric types.\n",
    "    - **`def clean_and_impute_numeric_columns`**: This function cleans and imputes numeric columns by filling missing values with the median value of each column.\n",
    "    - **`def impute_categorical_columns`**: This function imputes missing values in categorical columns with a constant value, 'Unknown', ensuring no missing values remain.\n",
    "\n",
    "2. **Date Conversion and Season Column Creation**\n",
    "    - **`def convert_date_columns`**: This function standardizes date formats to ensure consistency across the dataset. It addresses issues where date values may be in different formats.\n",
    "    - **`def create_season_column`**: Recognizing that the original `Cre_date` column was not contributing effectively to the model, this function creates a new 'Season' column based on the month extracted from `Cre_date`.\n",
    "\n",
    "3. **Derived Feature Creation**\n",
    "    - **`def create_derived_features`**: Through analysis, we identified key columns that significantly impact the model's performance. This function creates new features based on these important columns, enhancing the model's predictive power.\n",
    "\n",
    "4. **Dropping Unnecessary Columns**\n",
    "    - **`def drop_unnecessary_columns`**: Based on the model's performance results and prior knowledge, this function removes columns that are deemed unnecessary. This step is crucial for improving the model's efficiency and reducing its complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82695d04-cc34-45ab-a793-ce4247055b14",
   "metadata": {},
   "source": [
    "## Load the dataframe, and prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23012bc8-09cb-48f9-a424-b70a5b2d4f2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_url = 'https://raw.githubusercontent.com/nadav52/Matala-2/main/dataset.csv'\n",
    "df = pd.read_csv(raw_url, engine='python')\n",
    "\n",
    "# Prepare data\n",
    "prepared_df = prepare_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98cfcbbb-6bc7-4abc-b0cf-e8fa561cfdaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define columns\n",
    "cat_columns = ['manufactor', 'model', 'Gear', 'Engine_type', 'Area', 'City', 'Color', 'Prev_ownership', 'Curr_ownership']\n",
    "numeric_columns = ['capacity_Engine', 'Km', 'Pic_num', 'Year', 'Hand', 'Age', 'Km_per_year', 'Age_Hand_interaction']\n",
    "\n",
    "\n",
    "X = prepared_df.drop(columns=['Price'])\n",
    "y = prepared_df['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73035b4e-5a4a-4940-8dd8-4e3feaf57c55",
   "metadata": {},
   "source": [
    "#### Defining Categorical and Numeric Columns\n",
    "\n",
    "Defining `cat_columns` and `numeric_columns` before splitting ensures consistent preprocessing for both training and test sets, preserving feature engineering integrity.\n",
    "\n",
    "#### Train-Test Split\n",
    "\n",
    "- **`test_size=0.2`**: Uses 20% of the data for testing, balancing between sufficient training data and a reliable test set.\n",
    "- **`random_state=42`**: Ensures reproducibility, with `42` being a common choice for consistency across runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33021fab-11a6-4f49-9f8e-0844d0de753b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_columns),\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), cat_columns)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Get feature names\n",
    "feature_names_cat = []\n",
    "for i, col in enumerate(cat_columns):\n",
    "    feature_names_cat.extend([f\"{col}_{val}\" for val in preprocessor.named_transformers_['cat'].categories_[i]])\n",
    "feature_names = numeric_columns + feature_names_cat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df0b3a6-de42-4a38-a2ce-5a900bf8ce0d",
   "metadata": {},
   "source": [
    "#### Defining the Preprocessor\n",
    "\n",
    "The `preprocessor` is defined to apply different transformations to numeric and categorical columns, ensuring the data is standardized and properly encoded for the model.\n",
    "\n",
    "#### Fitting and Transforming the Data\n",
    "\n",
    "- **`X_train_transformed` and `X_test_transformed`**: The preprocessor is fitted on the training data and then applied to both training and test sets, maintaining consistency in preprocessing.\n",
    "\n",
    "#### Generating Feature Names\n",
    "\n",
    "- **`feature_names_cat`**: Extracts and formats the feature names for the encoded categorical variables, combining them with the numeric feature names for a complete list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0325ec83-8cb1-4fd4-8f84-7228c6d2c895",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = ElasticNet(random_state=42)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 1.5],\n",
    "    'l1_ratio': [0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find best parameters\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Use best parameters to evaluate model using cross-validation on training set\n",
    "best_model = grid_search.best_estimator_\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(best_model, X_train_transformed, y_train, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ce873-3975-4f0a-88fa-717965808c86",
   "metadata": {},
   "source": [
    "#### Parameter Grid for GridSearchCV\n",
    "\n",
    "- **`param_grid`**: Specifies the range of hyperparameters (`alpha` and `l1_ratio`) to search for optimal values. Hyperparameters are parameters whose values are set before the learning process begins and control the model's learning process.\n",
    "\n",
    "#### Performing GridSearchCV\n",
    "\n",
    "- **`grid_search`**: Uses 10-fold cross-validation to find the best hyperparameters, optimizing for negative mean squared error.\n",
    "\n",
    "  - **`scoring='neg_mean_squared_error'`**: This scoring method evaluates models based on the negative mean squared error, with lower values indicating better model performance.\n",
    "  - **`n_jobs=-1`**: Utilizes all available CPU cores for parallel processing, speeding up the computation.\n",
    "\n",
    "#### Evaluating the Model\n",
    "\n",
    "- **`best_model`**: The best estimator from `GridSearchCV`.\n",
    "- **`cross_val_score`**: Evaluates the model using 10-fold cross-validation on the training set to ensure robust performance metrics.\n",
    "\n",
    "  - **`KFold(n_splits=10, shuffle=True, random_state=42)`**: Splits the data into 10 folds for cross-validation, shuffling the data to ensure randomness and setting a seed for reproducibility.\n",
    "  \n",
    "\n",
    "\n",
    "This code optimizes an ElasticNet model through GridSearchCV for hyperparameter tuning and K-Fold cross-validation for performance assessment, aiming to balance bias and variance, reduce overfitting, and ensure robust performance on unseen data by systematically exploring combinations of alpha and l1_ratio to find the best model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0473733c-9405-4684-824a-9b4ae144a213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit model on training data using best parameters\n",
    "best_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test_transformed)\n",
    "mse = mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "97c04398-dde9-4372-9ffa-0a0c8b6a3073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate permutation importance using training set\n",
    "importance = permutation_importance(best_model, X_train_transformed, y_train, n_repeats=10, random_state=42)\n",
    "feature_importances = importance.importances_mean\n",
    "\n",
    "# Create a dictionary for permutation importance\n",
    "importance_dict = dict(zip(feature_names, feature_importances))\n",
    "sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get model coefficients\n",
    "coefficients = best_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b57c06-30f1-48bf-8e1a-13c519f8cbfc",
   "metadata": {},
   "source": [
    "This code calculates permutation importance and extracts model coefficients to identify influential features. Permutation importance measures each feature's impact on model performance by randomly shuffling its values and observing the resulting change in model error. Model coefficients indicate feature weights in the ElasticNet model. Together, these methods provide complementary insights into feature relevance, aiding in model interpretation and potential feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22da4943-b066-4c51-a661-fdca57db30d1",
   "metadata": {},
   "source": [
    "## Resultes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d847f2da-dd90-4bc0-a7d7-3c7b071af3dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE : 12193.038824847848\n",
      "\n",
      "Top 5 most influential features:\n",
      "Age_Hand_interaction: 0.6254, Coefficient = 12363.2374 (positive impact)\n",
      "Hand: 0.3235, Coefficient = -8918.8116 (negative impact)\n",
      "Year: 0.2649, Coefficient = 8020.7990 (positive impact)\n",
      "Age: 0.2647, Coefficient = -8018.8019 (negative impact)\n",
      "Km: 0.2479, Coefficient = -7638.0475 (negative impact)\n"
     ]
    }
   ],
   "source": [
    "print('The RMSE : ' + str(np.sqrt(mse)))  \n",
    "\n",
    "\n",
    "\n",
    "# Print top 5 most influential features with scaled permutation importance\n",
    "print(\"\\nTop 5 most influential features:\")\n",
    "for feature, importance_value in sorted_importances[:5]:\n",
    "    coefficient_index = feature_names.index(feature)\n",
    "    coefficient_value = coefficients[coefficient_index]\n",
    "    sign = \"positive\" if coefficient_value > 0 else \"negative\"\n",
    "    print(f\"{feature}: {importance_value:.4f}, Coefficient = {coefficient_value:.4f} ({sign} impact)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d760f7c1-e115-46f6-bdb4-8b0edf17684d",
   "metadata": {},
   "source": [
    "---\n",
    "The RMSE (Root Mean Squared Error) measures the average prediction error of the model, calculated here as 12193.0388. Lower RMSE values indicate better model accuracy. RMSE value of 12193.0388 indicates solid predictive accuracy for estimating car prices.\n",
    "\n",
    "Top 5 Influential Features:\n",
    "- **Age_Hand_interaction**: Positive impact (Coefficient: 0.6254, Value: 12363.2374). Indicates higher car prices with increased interaction between age and hand.\n",
    "- **Hand**: Negative impact (Coefficient: 0.3235, Value: -8918.8116). Suggests lower prices for cars with fewer previous owners.\n",
    "- **Year**: Positive impact (Coefficient: 0.2649, Value: 8020.7990). Newer cars tend to have higher predicted prices.\n",
    "- **Age**: Negative impact (Coefficient: 0.2647, Value: -8018.8019). Older cars generally predict lower prices.\n",
    "- **Km**: Negative impact (Coefficient: 0.2479, Value: -7638.0475). Higher mileage correlates with lower predicted prices.\n",
    "\n",
    "These insights help understand how each feature influences car price predictions in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad44e2e-19b9-4e10-8fcb-fb40349b16e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
